{"cells":[{"cell_type":"code","source":["pip install azureml-mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebd54d98-58ae-47d0-a8b3-4adcb2c148b7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84c71e0a-16bf-4d79-bc3c-999a7ded46dc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType,StructField, StringType, IntegerType,DoubleType\n# File location and type\nfile_location = \"/FileStore/tables/sample_v1.csv\"\n\nfile_type = \"csv\"\n# CSV options\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n'''\nReading sample enqs\n'''\nschema = StructType([ \\\n    StructField(\"id\",IntegerType(),True), \\\n    StructField(\"en_inst\",StringType(),True), \\\n    StructField(\"date\",StringType(),True), \\\n    StructField(\"amount\", DoubleType(), True), \\\n    StructField(\"enq_class\", StringType(), True), \\\n    StructField(\"enq_cust\", StringType(), True) \\\n  ])\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"schema\", schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndisplay(df)\n'''\nReading sample flagged file\n'''\nfile_location1 = \"/FileStore/tables/flag-1.csv\"\nschema1 = StructType([ \\\n    StructField(\"enq_cust\",StringType(),True), \\\n    StructField(\"flag\",IntegerType(),True), \\\n    \n  ])\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf1 = spark.read.format(file_type) \\\n  .option(\"schema\", schema1) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location1)\ndf1=df1.filter(\"\"\"enq_cust!='10000'\"\"\")\ndisplay(df1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"526422f5-6564-48c7-a093-94b4dc0e11be"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nfrom  datetime import datetime\nimport numpy as np\nfile=df.toPandas()\nfile=file[file.enq_cust!='10000']\nfile['date']=pd.to_datetime(file.date,dayfirst='true')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc76dc8c-3b41-47ef-ac35-af06ea142767"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nFilter and feature generator\n'''\ndef feature_mom_gen(file,last_date,filter_mon,grp_cols,date,agg_cols,renam_cols):\n    past_date = datetime.strptime(last_date,'%Y-%m-%d') -pd.DateOffset(months=filter_mon)\n    tmp=file[np.logical_and(file[date]<=last_date,file[date]>=past_date)]\n    t=tmp.groupby(grp_cols,as_index=False).agg(agg_cols)\n    t.columns=renam_cols\n    return(t)\n\n'''\nColumn name standizer\n'''\ndef name_standard(frame,id,columns):\n    c=frame.columns[~frame.columns.isin(columns)]\n    c=c[~c.isin(id)]\n    df=pd.DataFrame()\n    p=[]\n    for k in c:\n        frame1 = pd.pivot_table(frame, values =k, index =id,columns=columns,\n                              aggfunc = np.sum)\n        cols=frame1.columns\n        a=[]\n        for i in np.arange(len(cols)):\n            \n            tmp=''\n            for j in np.arange(len(cols[i])):\n                tmp+=cols[i][j]+'_'\n            tmp=k+'_'+tmp\n            a.append(tmp)\n        \n        b=['enq_cust']\n        b.extend(a)\n        df=frame1.reset_index()\n        df.columns=b\n        p.append(df)\n    df=pd.DataFrame()\n    for i in p:\n        if len(df)==0:\n            df=i\n        else:\n            df=df.merge(i,how='left',left_on=['enq_cust'],right_on=['enq_cust'])\n  \n    return df\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"013e8ee2-2b5f-4bd2-a3a2-46dbc0b034e5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nEnq Rollup\n'''\ndef enq_rllup(file,last_date):\n    '''\n    Enq Inst level rollup\n    '''\n    feature_base=((feature_mom_gen(file,last_date,20,['en_inst','enq_class','enq_cust'],'date',{'amount':['sum','count']},['en_inst','enq_class','enq_cust','sum_amt_20m','cnt_20m']).merge(\n                   feature_mom_gen(file,last_date,9,['en_inst','enq_class','enq_cust'],'date',{'amount':['sum','count']},['en_inst','enq_class','enq_cust','sum_amt_9m','cnt_9m']),how='left')).merge(\n        feature_mom_gen(file,last_date,6,['en_inst','enq_class','enq_cust'],'date',{'amount':['sum','count']},['en_inst','enq_class','enq_cust','sum_amt_6m','cnt_6m']),how='left')).merge(\n        feature_mom_gen(file,last_date,3,['en_inst','enq_class','enq_cust'],'date',{'amount':['sum','count']},['en_inst','enq_class','enq_cust','sum_amt_3m','cnt_3m']),how='left')\n\n    feature_base=name_standard(feature_base,['enq_cust'],['en_inst','enq_class'])\n    feature_base=feature_base.fillna(0)\n    \n    '''\n    Enq Class level rollup\n    '''\n    feature_base1=((feature_mom_gen(file,last_date,20,['enq_class','enq_cust'],'date',{'amount':['sum','count']},['enq_class','enq_cust','sum_amt_250m','cnt_20m']).merge(\n        feature_mom_gen(file,last_date,9,['enq_class','enq_cust'],'date',{'amount':['sum','count']},['enq_class','enq_cust','sum_amt_9m','cnt_9m']),how='left')).merge(\n        feature_mom_gen(file,last_date,6,['enq_class','enq_cust'],'date',{'amount':['sum','count']},['enq_class','enq_cust','sum_amt_6m','cnt_6m']),how='left')).merge(\n        feature_mom_gen(file,last_date,3,['enq_class','enq_cust'],'date',{'amount':['sum','count']},['enq_class','enq_cust','sum_amt_3m','cnt_3m']),how='left')\n    feature_base1=name_standard(feature_base1,['enq_cust'],['enq_class'])\n    feature_base1=feature_base1.fillna(0)\n    \n    \n    '''\n    Enq cust level rollup\n    '''\n    feature_base2=((feature_mom_gen(file,last_date,20,['enq_cust'],'date',{'amount':['sum','count']},['enq_cust','sum_amt_250m','cnt_20m']).merge(\n        feature_mom_gen(file,last_date,9,['enq_cust'],'date',{'amount':['sum','count']},['enq_cust','sum_amt_9m','cnt_9m']),how='left')).merge(\n        feature_mom_gen(file,last_date,6,['enq_cust'],'date',{'amount':['sum','count']},['enq_cust','sum_amt_6m','cnt_6m']),how='left')).merge(\n        feature_mom_gen(file,last_date,3,['enq_cust'],'date',{'amount':['sum','count']},['enq_cust','sum_amt_3m','cnt_3m']),how='left')\n    feature_base2=feature_base2.fillna(0)\n\n\n    feature_base_final=(feature_base.merge(feature_base1,how='left',left_on=['enq_cust'],right_on=['enq_cust'])).merge(feature_base2,how='left',left_on=['enq_cust'],right_on=['enq_cust'])\n    feature_base_final.fillna(0)\n    \n    feature_base_final=(feature_base.merge(feature_base1,how='left',left_on=['enq_cust'],right_on=['enq_cust'])).merge(feature_base2,how='left',left_on=['enq_cust'],right_on=['enq_cust'])\n    feature_base_final.fillna(0)\n    \n    \n    for i in feature_base_final.columns:\n        if i!='enq_cust':\n            feature_base_final[i]=feature_base_final[i].astype('float64')\n\n    return(feature_base_final)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4921eef5-30b2-43f2-88a2-834d1218c0c0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["feature_base_final=enq_rllup(file,'2021-03-31')\nfeature_base_final"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cff8621-4224-4f7b-905e-782d4c27d62a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n--Creating database for persisting features\n--drop DATABASE enq_feature_store1;\nCREATE DATABASE IF NOT EXISTS enq_feature_store4;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff446916-fe77-4556-9485-cae835131659"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nCreate storage of features\n'''\nfrom databricks import feature_store\n\nfs=feature_store.FeatureStoreClient()\nfs.create_feature_table(\n    name='enq_feature_store4.feature_base_final',\n    keys=['enq_cust'],\n    features_df=spark.createDataFrame(feature_base_final),\n    partition_columns=['enq_cust'],\n    description='ENQ INST level',\n    \n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06c88abe-12d4-4384-a590-9f18923e9e4a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nFeature lookup\n'''\nfrom databricks.feature_store import feature_table\nfrom databricks.feature_store import FeatureLookup\nfeature_names=spark.sql('''Select * from enq_feature_store4.feature_base_final limit 10''').toPandas()\nfeature_names=feature_names.drop(columns=['enq_cust'])\nfeature_lookups = [\n    FeatureLookup(\n      table_name = 'enq_feature_store4.feature_base_final',\n      feature_names = list(feature_names.columns),\n      lookup_key = 'enq_cust',\n    )\n  ]\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09d59b9b-e8ff-4fe4-a849-cd85533436ee"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from mlflow import pyfunc\nmlflow.end_run()\n \n# Start an mlflow run, which is needed for the feature store to log the model\nmlflow.start_run() \n \n# Create the training set that includes the raw input data merged with corresponding features from both feature tables\ntraining_set = fs.create_training_set(\n  df1,\n  feature_lookups = feature_lookups,\n  label = \"flag\",\n  exclude_columns = 'enq_cust'\n)\n \n# Load the TrainingSet into a dataframe which can be passed into sklearn for training a model\ntraining_df = training_set.load_df()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e58a2a47-ccb6-4f70-aebf-7286047563b4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(training_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe7934d9-d323-46e0-aae5-aa0bffd3d3db"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\nfrom mlflow.tracking import MlflowClient\nimport lightgbm as lgb\nimport mlflow.lightgbm\nfrom mlflow.models.signature import infer_signature\n \nfeatures_and_label = training_df.columns\n \n# Collect data into a Pandas array for training\ndata = training_df.toPandas()[features_and_label].fillna(0)\n \ntrain, test = train_test_split(data, random_state=123)\nX_train = train.drop([\"flag\"], axis=1)\nX_test = test.drop([\"flag\"], axis=1)\ny_train = train.flag\ny_test = test.flag\n \nmlflow.lightgbm.autolog()\ntrain_lgb_dataset = lgb.Dataset(X_train, label=y_train.values)\ntest_lgb_dataset = lgb.Dataset(X_test, label=y_test.values)\n \nparam = {\"num_leaves\": 32, \"objective\": \"binary\", \"metric\": \"logloss\"}\nnum_rounds = 100\n \n# Train a lightGBM model\nmodel = lgb.train(\n  param, train_lgb_dataset, num_rounds\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37473992-6131-432d-9ae2-bfbb7a3fbbf0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nREgister model\n'''\nfs.log_model(\n  model,\n  artifact_path=\"model_packaged\",\n  flavor=mlflow.lightgbm,\n  training_set=training_set,\n  registered_model_name=\"enq_sample_model\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d71b4cc4-751c-432d-9726-5c5cd262cf54"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nLatest version of model\n'''\ndef get_latest_model_version(model_name):\n  latest_version = 1\n  mlflow_client = MlflowClient()\n  for mv in mlflow_client.search_model_versions(f\"name='{model_name}'\"):\n    version_int = int(mv.version)\n    if version_int > latest_version:\n      latest_version = version_int\n  return latest_version\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"582722d9-5dce-41cd-822a-6dec298b013d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["latest_model_version = get_latest_model_version(\"enq_sample_model\")\nmodel_uri = f\"models:/enq_sample_model/{latest_model_version}\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd0681b3-9ce4-4d0d-8897-fcd23c301fd6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model_uri"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a52ab7d0-995e-4a6a-abd8-86c52c9a9a20"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"sample_dep","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2559865829634594}},"nbformat":4,"nbformat_minor":0}
